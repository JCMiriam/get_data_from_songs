{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de uso de la función para obtener nuevos recording_ids\n",
    "\n",
    "`df = pd.read_csv(ruta_al_dataset_a_procesar.csv)`\n",
    "\n",
    "`get_recording_id(df)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para obtener nuevos recording_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recording_id(df):\n",
    "    # Función para obtener el recording_id desde la API de MusicBrainz\n",
    "    def get_recording_id(title, artist):\n",
    "        query = f'recording:\"{title}\" AND artist:\"{artist}\"'\n",
    "        url = f\"https://musicbrainz.org/ws/2/recording/?query={query}&fmt=json\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)  # Agregar timeout para evitar bloqueos indefinidos\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if \"recordings\" in data and len(data[\"recordings\"]) > 0:\n",
    "                    return data[\"recordings\"][0][\"id\"]\n",
    "            return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error on search '{title}' - '{artist}': {e}\")\n",
    "            return None\n",
    "\n",
    "    # Rutas de los archivos de salida\n",
    "    found_file = \"../data/raw/nuevos_ids_encontrados.csv.temp\"\n",
    "    not_found_file = \"../data/raw/ids_no_encontrados.csv.temp\"\n",
    "\n",
    "    # Crear los archivos si no existen\n",
    "    # En caso de que ya existan y tengan registros, en lugar de sobrescribirse, los nuevos se añaden al final\n",
    "    if not os.path.exists(found_file):\n",
    "        pd.DataFrame(columns=[\"artist_name\", \"song_name\", \"recording_id\"]).to_csv(found_file, index=False)\n",
    "    if not os.path.exists(not_found_file):\n",
    "        pd.DataFrame(columns=[\"artist_name\", \"song_name\"]).to_csv(not_found_file, index=False)\n",
    "\n",
    "    # Inicializar contadores\n",
    "    total_requests = 0\n",
    "\n",
    "    # Procesar el DataFrame\n",
    "    for index in df.index:\n",
    "        row = df.loc[index]\n",
    "\n",
    "        # Saltar filas con un recording_id ya existente y válido\n",
    "        if pd.notna(row[\"recording_id\"]) and row[\"recording_id\"] != \"Not found\":\n",
    "            continue\n",
    "\n",
    "        total_requests += 1\n",
    "        print(f\"\\n[Progress] Request {total_requests}/{len(df)}...\")\n",
    "\n",
    "        # Obtener el recording_id\n",
    "        recording_id = get_recording_id(row[\"song_name\"], row[\"artist_name\"])\n",
    "\n",
    "        # Procesar y guardar los resultados por cada request\n",
    "        # Es un poco más lento pero resulta en menos fallos, por lo que es preferible\n",
    "        if not recording_id:  # Si no se encuentra el recording_id, se almacenan los datos procesados en un dataset ids_no_encontrados.csv.temp\n",
    "            print(f\"  ⚠️ Not Recording ID found for: {row['song_name']} - {row['artist_name']}\")\n",
    "            not_found_df = pd.DataFrame([{\"artist_name\": row[\"artist_name\"], \"song_name\": row[\"song_name\"]}])\n",
    "            not_found_df.to_csv(not_found_file, mode=\"a\", index=False, header=False)\n",
    "        else:  # Si se encuentra el recording_id, se almacenan los datos procesados en un dataset nuevos_ids_encontrados.csv.temp\n",
    "            print(f\"  ✅ Recording ID found: {recording_id}\")\n",
    "            found_df = pd.DataFrame([{\n",
    "                \"artist_name\": row[\"artist_name\"],\n",
    "                \"song_name\": row[\"song_name\"],\n",
    "                \"recording_id\": recording_id\n",
    "            }])\n",
    "            found_df.to_csv(found_file, mode=\"a\", index=False, header=False)\n",
    "\n",
    "\n",
    "        # Respetar el límite de velocidad de la API\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(f\"\\nProcessing complete. Results saved in:\\n - Found: {found_file}\\n - Not Found: {not_found_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener nuevos recording_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ruta_del_dataset_a_procesar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recording_id(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez termine o se corte la ejecución, los datos de los que se ha encontrado recording_id estarán en [nuevos_ids_encontrados.csv.temp](../data/raw/nuevos_ids_encontrados.csv.temp) y los que no se encuentren, en [ids_no_encontrados.csv.temp](../data/raw/ids_no_encontrados.csv.temp).\n",
    "\n",
    "En caso de que se vuelva a ejecutar la función, si los archivos ya existen y contienen datos, estos no se sobreescriben, sino que se añaden al final. Para evitar duplicados y ahorrar tiempo, lo ideal es eliminar los datos que ya están en [nuevos_ids_encontrados.csv.temp](../data/raw/nuevos_ids_encontrados.csv.temp) y [ids_no_encontrados.csv.temp](../data/raw/ids_no_encontrados.csv.temp) del dataset a procesar. Para ello tenemos la función [remove_existing_records()](eliminar-de-un-dataset-que-existen-en-otro.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
